# -*- coding: utf-8 -*-
"""
Created on Sun Jun 27 11:13:15 2021

@author: flyki
"""
# -*- coding: utf-8 -*-
"""
Created on Sun Jun 13 14:21:33 2021

@author: flyki
"""

import os
#os.environ["CUDA_VISIBLE_DEVICES"] = "0" # 0 for GPU
import os.path as osp
import sys
import time
import random
import joblib
import argparse
import torch
import pandas as pd
import numpy as np
from numpy import genfromtxt
import matplotlib.pyplot as plt
from sklearn import preprocessing
import sklearn.metrics as metrics
from sklearn.metrics import roc_auc_score,average_precision_score, roc_curve, auc, precision_recall_curve, f1_score
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.metrics.cluster import normalized_mutual_info_score
from sklearn.metrics.cluster import adjusted_rand_score
import torch_geometric.transforms as Trans
from torch_geometric.nn import GCNConv, GAE, VGAE
from torch_geometric.utils import train_test_split_edges
import torch.nn.functional as F
import torch.nn as nn
import math
from torch.nn.parameter import Parameter
from torch.nn.modules.module import Module
min_max_scaler = preprocessing.MinMaxScaler()
device = torch.device('cuda')
loss_fct = torch.nn.BCELoss()
Sigm = torch.nn.Sigmoid()

'''
####################################################     increased and decreased DDIs
'''
my_data = genfromtxt('D:\\Datasets\\DDI_DTI_datasets\\drug_drug\\adjacentDDI_Increase.csv',delimiter=',')
adjacentDD = my_data.astype('int')
my_data = genfromtxt('D:\\Datasets\\DDI_DTI_datasets\\drug_drug\\adjacentDDI_Decrease.csv',delimiter=',')
adjacentDD_decrease = my_data.astype('int')
nD = adjacentDD.shape[0]
DDlist = list()
for i in range(0,adjacentDD.shape[0]-1):
    for j in range(i+1,adjacentDD.shape[0]):
        if(adjacentDD[i,j]>0):
            DDlist.append([i,j])
print(len(DDlist))
random.shuffle(DDlist)

NonDDlist = list()
for i in range(0,adjacentDD_decrease.shape[0]-1):
    for j in range(i+1,adjacentDD_decrease.shape[0]):
        if(adjacentDD_decrease[i,j]==1):
            NonDDlist.append([i,j])
print(len(NonDDlist))
random.shuffle(NonDDlist)


'''
####################################################     features
'''
my_data = genfromtxt('D:\\Datasets\\DDI_DTI_datasets\\drug_drug\\drug_881fingerprint.csv',delimiter=',')
drug_feature_fingerprint = my_data.astype('int')
nF = drug_feature_fingerprint.shape[1]

'''
####################################################     model
'''

Hdim1 = 256
d = 64
Hdim3 = 32
Hdim4 = 16
drop = 0.2
class GraphConvolution(Module):
    def __init__(self, in_features, out_features, bias=True):
        super(GraphConvolution, self).__init__()
        self.in_features = in_features
        self.out_features = out_features
        self.weight = Parameter(torch.FloatTensor(in_features, out_features))
        if bias:
            self.bias = Parameter(torch.FloatTensor(out_features))
        else:
            self.register_parameter('bias', None)
        self.reset_parameters()

    def reset_parameters(self):
        stdv = 1. / math.sqrt(self.weight.size(1))
        self.weight.data.uniform_(-stdv, stdv)
        if self.bias is not None:
            self.bias.data.uniform_(-stdv, stdv)

    def forward(self, input, adj):
        support = torch.mm(input, self.weight)
        output = torch.spmm(adj, support)
        if self.bias is not None:
            return output + self.bias
        else:
            return output

    def __repr__(self):
        return self.__class__.__name__ + ' (' \
               + str(self.in_features) + ' -> ' \
               + str(self.out_features) + ')'

def reset_parameters(w):
    stdv = 1. / math.sqrt(w.size(0))
    w.data.uniform_(-stdv, stdv)

class IDGCN(nn.Module):
    def __init__(self, nfeat, nhid1, nhid2, nhid_decode1, nhid_decode2, dropout):
        super(IDGCN, self).__init__()
        
        # original graph
        self.o_gc1 = GraphConvolution(nfeat, nhid1)
        self.o_gc2 = GraphConvolution(nhid1, nhid2)
        
        # original graph for skip update
        self.o_gc1_s = GraphConvolution(nhid1, nhid1)
        
        #skip graph
        self.s_gc1 = GraphConvolution(nfeat, nhid1)
        
        #skip graph for original update
        self.s_gc1_o = GraphConvolution(nfeat, nhid1)
        self.s_gc2_o = GraphConvolution(nhid1, nhid2)
       
        self.dropout = dropout
        
        self.decoder1 = nn.Linear(nhid2 * 2, nhid_decode1)
        self.decoder2 = nn.Linear(nhid_decode1, nhid_decode2)
        self.decoder3 = nn.Linear(nhid_decode2, 1)
        
    def reparametrize(self, mu, logstd):
        if self.training:
            return mu + torch.randn_like(logstd) * torch.exp(logstd)
        else:
            return mu

    def forward(self, x, o_adj, s_adj, idx):
        
        o_x = F.relu(self.o_gc1(x, o_adj) + self.s_gc1_o(x, s_adj))       
        s_x = F.relu(self.s_gc1(x, s_adj) + self.o_gc1_s(o_x, o_adj))
        o_x = F.dropout(o_x, self.dropout, training = self.training)
        s_x = F.dropout(s_x, self.dropout, training = self.training)
        x = self.o_gc2(o_x, o_adj) + self.s_gc2_o(s_x, s_adj)
        feat_p1 = x[idx[0]] # the first biomedical entity embedding retrieved
        feat_p2 = x[idx[1]] # the second biomedical entity embedding retrieved
        feat = torch.cat((feat_p1, feat_p2), dim = 1)
        o = F.relu(self.decoder1(feat))
        o = F.relu(self.decoder2(o))
        o = torch.sigmoid(self.decoder3(o))
        return o, x

foldN = 5
foldrange = int(nddi_pos/foldN)
sampleT = np.arange(nddi_pos)
np.random.shuffle(sampleT)
sampleT = sampleT[0:foldrange*foldN].reshape((foldrange,foldN))

label_test = torch.Tensor(np.concatenate((np.ones([foldrange,]),np.zeros([foldrange,]))))
label_train = torch.Tensor(np.concatenate((np.ones([foldrange*(foldN-1),]),np.zeros([foldrange*(foldN-1),]))))
label_train = label_train.to(device)
label_test = label_test.to(device)
label_trainCPU = label_train.cpu().numpy()
label_testCPU = label_test.cpu().numpy()

max_auc = 0
def test(DDx, adj, adj2, inptest):
    model.eval()
    label_test_pred = []
    output, _ = model(DDx, adj, adj2, inptest)
    n = torch.squeeze(Sigm(output))
    loss = loss_fct(n, label_test)
    label_test_pred = label_test_pred + output.flatten().tolist()
    outputs = np.asarray([1 if i else 0 for i in (np.asarray(label_test_pred) >= 0.5)])
    label_test_pred = np.array(label_test_pred)
    roc = roc_auc_score(label_testCPU, label_test_pred)
    ap = average_precision_score(label_testCPU, label_test_pred)
    f1s = f1_score(label_testCPU, outputs)
    return roc, ap, f1s, loss
def train(DDx, adj, adj2, inptrain):
    model.train()
    optimizer.zero_grad()
    output, _ = model(DDx, adj, adj2, inptrain)
    n = torch.squeeze(Sigm(output))
    loss_train = loss_fct(n, label_train)
    loss_train.backward()
    optimizer.step()
    label_train_pred = output.flatten().tolist()
    return float(loss_train),label_train_pred
loss_history = []

adj = torch.Tensor(adjacentDD).type(torch.float)
adj2 = torch.Tensor(adjacentDD_decrease).type(torch.float)

model_str = ['drug_feature_enzyme','drug_feature_side','drug_feature_pathway','drug_feature_target',
             'drug_feature_PRL','drug_feature_adjacentDD','drug_feature_fingerprint','drug_feature_node2vec']

DDx = torch.from_numpy(drug_feature_fingerprint).type(torch.float)
DDx = DDx.to(device)
dplist=[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]

Hdim1 = 128
d = 64
Hdim3 = 32
Hdim4 = 16
Nfeature = DDx.shape[1]

for drop in dplist:
    print('Dropout: ',drop)
    inter_auc=list()
    inter_pr = list()
    for repeat in range(0,5):
        model = IDGCN(nfeat=Nfeature,nhid1=Hdim1,nhid2=d,nhid_decode1 = Hdim3,nhid_decode2=Hdim4,dropout=drop)
        optimizer = torch.optim.Adam(model.parameters(),lr=0.001, weight_decay=0.0005)
        model = model.to(device)
        model.eval()
        for T in range(0,foldN):
            max_auc = 0.01
            max_loss = 30000
            EpochSize = 400
            zpath = 'D:\\StudyTools\\GraphModels\\zzzzz\\z_'+str(drop)+'_drug_feature_target_Repeat'+str(repeat)+'_'+str(T)+'.csv'
            modelpath = 'D:\\StudyTools\\GraphModels\\temp1\\modelall'+str(T)+'.pth'
            adpathP = 'D:\\Datasets\\DDI_DTI_datasets\\drug_drug\\AdjacentNet_Pos_'+str(T)+'.csv'
            adpathN = 'D:\\Datasets\\DDI_DTI_datasets\\drug_drug\\AdjacentNet_Neg_'+str(T)+'.csv'
            my_data = genfromtxt(adpathP,delimiter=',')
            my_data = my_data.astype('int')
            adj = torch.Tensor(my_data).type(torch.float)
            adj = adj.to(device)
            #DDx = torch.Tensor(my_data).type(torch.float)
            #DDx = DDx.to(device)
            my_data = genfromtxt(adpathN,delimiter=',')
            my_data = my_data.astype('int')
            adj2 = torch.Tensor(my_data).type(torch.float)
            adj2 = adj2.to(device)
        
            sampleN_test = sampleT[:,T]
            sampleN_test = sampleN_test.reshape((1,foldrange))
            sampleN_test = sampleN_test[0]
            sampleN_train = np.delete(sampleT,T,axis=1)
            sampleN_train = sampleN_train.reshape((1,foldrange*(foldN-1)))
            sampleN_train = sampleN_train[0]
    
            inptrain=[0,1]
            inptrain[0] = np.concatenate((ddiedgeP[sampleN_train,0],ddiedgeN[sampleN_train,0]))
            inptrain[1] = np.concatenate((ddiedgeP[sampleN_train,1],ddiedgeN[sampleN_train,1]))
            inptrain = torch.Tensor(inptrain).type(torch.LongTensor)
            inptrain = inptrain.to(device)
            inptest = [0,1]
            inptest[0] = np.concatenate((ddiedgeP[sampleN_test,0],ddiedgeN[sampleN_test,0]))
            inptest[1] = np.concatenate((ddiedgeP[sampleN_test,1],ddiedgeN[sampleN_test,1]))
            inptest = torch.Tensor(inptest).type(torch.LongTensor)
            inptest = inptest.to(device)
    
            loss_train_history = np.ones([EpochSize,])*100
            loss_test_history = np.ones([EpochSize,])*100
            xaxis = np.arange(0,EpochSize,1)
            roc_train = np.zeros([EpochSize,])
            roc_test = np.zeros([EpochSize,])
            for epoch in range(0,EpochSize):
                loss_train,label_train_pred = train(DDx, adj, adj2, inptrain)
                label_train_pred = torch.Tensor(label_train_pred)
                loss_train_history[epoch]=loss_train
                label_train_predCPU = label_train_pred.cpu().numpy()
                roc_train[epoch] = roc_auc_score(label_trainCPU, label_train_predCPU)
                roc_val, prc_val, f1_val, loss_val = test(DDx, adj, adj2, inptest)
                loss_test_history[epoch] = loss_val
                roc_test[epoch]=roc_val
        #if(roc_val>max_auc):
                if(loss_val<max_loss):
                    max_loss = loss_val
                    max_auc = roc_val
                    torch.save(model.state_dict(),modelpath)
            #print("Save model at {:03d}th epoch, LossTrain: {:.5f}, LossTest: {:.5f}, RocTest: {:.5f}".format(epoch+1, loss_train, loss_val, roc_val))
        #print('Epoch: {:03d}, LossTrain: {:.5f}, LossTest: {:.5f}, RocTest: {:.5f}'.format(epoch+1, loss_train, loss_val, roc_val))
            print('T=',T)
            model_loaded = model.load_state_dict(torch.load(modelpath))
            output, codelayer = model(DDx, adj, adj2, inptest)
            zz=codelayer.detach().to('cpu').numpy()
            np.savetxt(zpath,zz,delimiter=",")
            if(T==0):
                label_p = output
            else:
                label_p = torch.cat((label_p,output),0)
        label_test = torch.Tensor(np.concatenate((np.ones([foldrange,]),np.zeros([foldrange,]))))
        label_test = label_test.to(device)
        label_t = torch.cat((label_test,label_test,label_test,label_test,label_test))
        label_t = label_t.cpu().numpy().tolist()
        label_p = label_p.cpu().detach().numpy()
        label_p = label_p.reshape(len(label_t),)
        label_p = list(label_p)
        print('Repeat No.: ',repeat+1)
#from sklearn.metrics import roc_auc_score,average_precision_score, roc_curve, auc, precision_recall_curve
        fpr,tpr,threshold = roc_curve(label_t, label_p, pos_label=1)
        from sklearn import metrics as sklearnmetrics
        roc_auc = sklearnmetrics.auc(fpr, tpr)
        print('AUCROC: ', roc_auc)
        precision, recall, thresholdPR = precision_recall_curve(label_t, label_p)
        pr_auc = sklearnmetrics.auc(recall,precision)
        print('AUCPR', pr_auc)
        print('##############################')
        inter_auc.append(roc_auc)
        inter_pr.append(pr_auc)
        print('##############################')
        inter = inter_auc+inter_pr
    np.savetxt('D:\\StudyTools\\GraphModels\\zzzzz\\drop_target_'+str(drop)+'.csv',np.array(inter),delimiter=",")



